import os
from dotenv import load_dotenv
from pathlib import Path
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient
from langchain.vectorstores import FAISS
from langchain.schema import Document
from langchain.embeddings.base import Embeddings
from typing import List
import re
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline

load_dotenv()  

class TextFileLoader:
    def __init__(self, folder_path: str):
        self.folder_path = Path(folder_path)
        if not self.folder_path.exists():
            raise FileNotFoundError(f"Percorso non trovato: {folder_path}")
        if not self.folder_path.is_dir():
            raise NotADirectoryError(f"Non √® una directory: {folder_path}")

    def load(self) -> list[dict]:
        """
        Legge tutti i file .txt nel percorso specificato.
        Ritorna: lista di dizionari con 'file_name' e 'content'
        """
        results = []
        for file in self.folder_path.glob("*.txt"):
            try:
                content = file.read_text(encoding="utf-8")
                results.append({
                    "file_name": file.name,
                    "content": content
                })
            except Exception as e:
                print(f"Errore nella lettura di {file.name}: {e}")
        return results
    

    
class AIProjectClientDefinition:
    def __init__(self):
        self.endpoint = os.getenv("PROJECT_ENDPOINT") 

        self.client = AIProjectClient(
            endpoint=self.endpoint,
            azure_endpoint=self.endpoint,
            credential=DefaultAzureCredential(),
        )


class AdaEmbeddingModel(AIProjectClientDefinition):
    def __init__(self, client_class: AIProjectClientDefinition, model_name: str = "text-embedding-ada-002"):
        self.client = client_class.client
        self.model_name = model_name
        self.azure_client = client_class.client.inference.get_azure_openai_client(api_version="2023-05-15")


    def embed_text(self, text: str) -> list[float]:
        response = self.azure_client.embeddings.create(
            input=[text],
            model=self.model_name
        )
        return response.data[0].embedding



class LangchainAdaWrapper(Embeddings):
    def __init__(self, ada_model: AdaEmbeddingModel):
        self.ada_model = ada_model

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return [self.ada_model.embed_text(text) for text in texts]

    def embed_query(self, text: str) -> List[float]:
        return self.ada_model.embed_text(text)
    


class TextAnonymizer:
    def __init__(self):
        model_name = "dslim/bert-base-NER"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForTokenClassification.from_pretrained(model_name)
        self.ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

        self.regex_patterns = {
            "IBAN": r"\b[A-Z]{2}[0-9]{2}[A-Z0-9]{11,30}\b",
            "CF": r"\b[A-Z]{6}[0-9]{2}[A-Z][0-9]{2}[A-Z][0-9]{3}[A-Z]\b",
            "PHONE": r"\b(\+?\d{1,3}[\s\-]?)?\(?\d{2,4}\)?[\s\-]?\d{5,8}\b"
        }

        self.entity_mask_map = {
            "PER": "[NOME]",
            "LOC": "[INDIRIZZO]",
            "ORG": "[AZIENDA]",
            "MISC": "[VARIABILE]",
            "IBAN": "[IBAN]",
            "CF": "[CF]",
            "PHONE": "[TELEFONO]"
        }

    def mask_text(self, text: str) -> str:
        masked_text = text

        # Applica regex
        for label, pattern in self.regex_patterns.items():
            matches = re.findall(pattern, masked_text)
            for match in matches:
                masked_text = masked_text.replace(match, self.entity_mask_map.get(label, "[SENSIBILE]"))

        # Applica NER
        entities = self.ner_pipeline(masked_text)
        for ent in sorted(entities, key=lambda x: x["start"], reverse=True):
            original = masked_text[ent['start']:ent['end']]
            label = ent['entity_group']
            if label in self.entity_mask_map:
                masked_text = masked_text[:ent['start']] + self.entity_mask_map[label] + masked_text[ent['end']:]

        return masked_text




class ChatCompletionModel(AIProjectClientDefinition):
    def __init__(self, client_class: AIProjectClientDefinition, model_name: str = "gpt-4o"):
        self.client = client_class.client
        self.model_name = model_name
        self.azure_client = client_class.client.inference.get_azure_openai_client(api_version="2025-01-01-preview")

    def ask_about_document(self, content: str, question: str) -> str:
        messages = [
            {
                "role": "system",
                "content": (
                    "Sei un assistente AI specializzato nell'analisi e nella classificazione di documenti testuali."
                ),
            },
            {
                "role": "user",
                "content": f"Documento:\n{content}\n\nDomanda: {question}"
            }
        ]

        response = self.azure_client.chat.completions.create(
            model=self.model_name,
            messages=messages,
            max_tokens=512,
            temperature=0.7,
            top_p=1.0,
        )
        return response.choices[0].message.content


class RAGPipeline:
    def __init__(self, folder_path: str):
        self.anonymizer = TextAnonymizer()
        loader = TextFileLoader(folder_path)
        results = loader.load()

        ai_client = AIProjectClientDefinition()
        ada_model = AdaEmbeddingModel(ai_client)
        embedding_wrapper = LangchainAdaWrapper(ada_model)

        documents = [
            Document(page_content=doc["content"], metadata={"file_name": doc["file_name"]})
            for doc in results
        ]
        vectorstore = FAISS.from_documents(documents, embedding=embedding_wrapper)
        self.retriever = vectorstore.as_retriever()
        self.chat_model = ChatCompletionModel(ai_client)

    def answer_query(self, query: str) -> str:
        docs_simili = self.retriever.get_relevant_documents(query)
        if not docs_simili:
            return "Nessun documento rilevante trovato."

        risposte = ""
        for doc in docs_simili:
            testo_anonimizzato = self.anonymizer.mask_text(doc.page_content)
            risposta = self.chat_model.ask_about_document(testo_anonimizzato, query)
            risposte += f"**{doc.metadata['file_name']}**\n‚ö†Ô∏è Il contenuto √® stato anonimizzato.\n{risposta}\n\n"

        return risposte


if __name__ == "__main__":
    folder_path = r"C:\DesktopNoOneDrive\ai-academy\Giorno_6\rag_documents"
    pipeline = RAGPipeline(folder_path)

    import gradio as gr
    with gr.Blocks(theme=gr.themes.Soft(), css="footer {display: none !important}") as demo:
        gr.Markdown(
            """
            # üìÑ RAG con Azure OpenAI
            Interroga i tuoi documenti locali con embeddings **Ada** e risposte da **GPT-4o**.  
            Inserisci una domanda qui sotto e ottieni risposte intelligenti basate sul contenuto.
            """,
            elem_id="title"
        )

        with gr.Row():
            with gr.Column(scale=1):
                query_input = gr.Textbox(
                    label="üß† Domanda",
                    placeholder="Es. Qual √® l‚Äôoggetto del documento X?",
                    lines=2,
                    interactive=True
                )
                submit_btn = gr.Button("Cerca tra i documenti", variant="primary")

            with gr.Column(scale=2):
                output_area = gr.Markdown(label="üìö Risposta")

        submit_btn.click(fn=pipeline.answer_query, inputs=query_input, outputs=output_area)

    demo.launch()